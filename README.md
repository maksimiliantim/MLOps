# Проектирование ML‑системы: Поиск и ранжирование товаров для e‑commerce

**Курс:** Проектирование систем машинного обучения  
**Уровень:** 2 курс магистратуры  
**Тема:** Ранжирование товаров по текстовому запросу с учётом релевантности и бизнес‑метрик. По аналогии с поиском на YouTube, спроектируйте систему для ранжирования товаров на основе текстового запроса. Сосредоточьтесь на сочетании релевантности текста с бизнес-метриками (например, коэффициент конверсии, маржа). 
**DAU:** 3 858 438  
**Пиковая нагрузка:** 12 051 RPS  
**SLA по задержке:** p95 ≤ 190 мс  

---

## Введение и постановка задачи

Поиск — один из ключевых сценариев в e‑commerce: пользователи формулируют намерение (intent) текстом, а платформа должна за доли секунды показать наиболее подходящие товары. При этом качество поиска определяется не только текстовой релевантностью, но и бизнес‑целями: конверсия в покупку, прибыльность, наличие товара, промо‑приоритеты и т.д.

**Задача проекта:** спроектировать ML‑систему ранжирования товаров по текстовому запросу, которая сочетает:
- **релевантность текста** (соответствие запросу и ожиданиям пользователя),
- **бизнес‑метрики** (конверсия/маржа/выручка),
- **устойчивость к высокой нагрузке** (до 12k RPS) и соблюдение SLA (≤ 190 мс).

### Ключевые бизнес‑метрики (цели)

1) **Search‑to‑Purchase Conversion (CVR/CR)** — доля поисковых сессий, завершающихся покупкой.  
2) **Profit / Margin per Search** — прибыль/маржа на один поисковый запрос (учёт маржи и доступности).  
3) **User Satisfaction proxy** — снижение доли «пустых» поисков и быстрых уходов (bounce), рост CTR@K как прокси удовлетворённости.

### Требования к системе

- **Latency:** p95 ≤ 190 мс на один запрос.  
- **Нагрузка:** 3 858 438 DAU, **пик 12 051 RPS**.  
- **Масштабируемость:** горизонтальное масштабирование сервисов поиска/ранжирования и индекса.  
- **Надёжность:** высокая доступность, деградация без «падения» (fallback), безопасные выкатки моделей.

---

## Часть 1. Формулировка ML‑задачи и выбор модели

### 1.1. Формулировка ML‑задачи

**Тип задачи:** ранжирование (Learning‑to‑Rank, LTR).

**Что нужно предсказывать:** упорядоченный список товаров для заданного запроса *q* (и контекста пользователя/сессии).

**Целевая переменная (таргет):**
- не хранится как «одна метка», а формируется из событий поведения:
  - показ → клик → добавление в корзину → покупка.
- практичный вариант — **graded relevance** (0…3), где метка зависит от «сильности» события:
  - 0 = показ без клика,
  - 1 = клик,
  - 2 = add‑to‑cart,
  - 3 = покупка,
  с возможным **временны́м затуханием** и фильтрацией «случайных» кликов.

**Обучающие примеры:**
- пары (query, item) из логов показов,
- отрицательные примеры: товары, показанные, но не выбранные,
- «сложные негативы»: товары из top‑N retrieval, которые похожи, но не кликнуты.

**Как смешиваем релевантность и бизнес‑сигналы:**
- в фичи ранжирования включаем **бизнес‑атрибуты**: маржа, наличие, промо, скорость доставки;
- при необходимости вводим **мягкие ограничения** (например, не поднимать отсутствующий товар) и **калибровку** вероятностей CTR/CVR.

---

### 1.2. Кандидатные модели

#### Вариант A: Gradient Boosted Decision Trees для LTR (LambdaMART / LightGBM Ranker)
**Плюсы:**
- быстрый инференс на CPU, хорошо вписывается в **SLA 190 мс**;
- устойчив к разнородным фичам (текстовые скоринги, бизнес‑метрики, агрегаты);
- интерпретируемость (важности фич), проще отлаживать.

**Минусы:**
- ограниченная способность «глубоко понимать» язык по сравнению с трансформерами;
- качество сильно зависит от качества retrieval и набора фич.

#### Вариант B: Transformer reranker (Cross‑Encoder) поверх top‑N кандидатов
**Плюсы:**
- высокая текстовая точность (особенно для сложных запросов и синонимов);
- лучше улавливает семантику и контекст.

**Минусы:**
- дорогой инференс (GPU/квантизация), риск не уложиться в 190 мс на пике;
- сложнее эксплуатация и предсказуемость latency.

### 1.3. Выбор

**Выбрано:** **двухэтапная схема Retrieval + LTR ранжирование**, где основная модель ранжирования — **LambdaMART (LightGBM Ranker)**, дополненная калибровкой (при необходимости).

**Обоснование:** на заданной нагрузке и SLA критична **предсказуемая задержка**, а LambdaMART даёт хороший баланс точности/стоимости и естественно комбинирует релевантность с бизнес‑фичами.

---

## Часть 2. Проектирование архитектуры

### 2.1. Высокоуровневая архитектура

**Поток онлайн‑запроса:**
1) Клиент (Web/Mobile) → CDN/Edge cache (часто повторяющиеся запросы).  
2) API Gateway → Rate limiter/Auth.  
3) Search Platform (Kubernetes):
   - Query Understanding (нормализация, spell, parse),
   - Retrieval (BM25/ANN) → кандидаты,
   - Feature Service (онлайн‑фичи: цена/наличие/маржа/CTR‑агрегаты),
   - Experiment Router (A/B, canary),
   - Ranking Service (LTR) → финальный Top‑K.
4) Результаты кешируются в Redis (TTL 1–5 мин) и/или пишутся в Results DB.
5) События (impressions/clicks/orders + latency) публикуются в Kafka для обучения и мониторинга.

**Офлайн‑контур:**
- Kafka → Data Lake (Iceberg/Parquet),
- batch‑обработка (Spark) → offline feature store + training datasets,
- обучение → model registry → controlled rollout (canary).
<img width="1429" height="711" alt="image" src="https://github.com/user-attachments/assets/cbfa9080-51bf-4022-bee7-83518f75bbda" />


---

### 2.2. Data Pipeline (сбор и подготовка данных)

**Источники данных:**
- Логи поисковых запросов, показов, кликов, корзины, заказов.
- Каталог товаров (название, описание, атрибуты, категории) и бизнес‑атрибуты (цена, маржа, наличие).

**Этапы:**
1) **Event Collector** принимает события и обогащает их (user/session ids, device, geo, experiment id).  
2) **Kafka** буферизует поток событий.  
3) **Data Lake (Iceberg/Parquet)** хранит сырые логи и снапшоты каталога.  
4) **Batch processing (Spark)** периодически:
   - собирает пары (query, item),
   - строит агрегаты (CTR/CVR по товарам/категориям/запросам),
   - считает текстовые фичи (BM25 score, embedding similarity),
   - формирует обучающие выборки (labeling).
5) Результаты сохраняются в:
   - **Offline Feature Store** (для обучения),
   - **Online Feature Store / KV** (для инференса),
   - **Training dataset** (готовая витрина под обучение LTR).

**Data Quality:**
- проверка схемы/долей пропусков,
- контроль свежести витрин,
- поиск выбросов (аномальные CTR/CVR, аномальные цены).
<img width="1164" height="337" alt="image" src="https://github.com/user-attachments/assets/26e2a1f0-b3b8-4387-be27-95b298d9f106" />

---

### 2.3. Training Pipeline (обучение и регистрация модели)

**Триггеры запуска:**
- по расписанию (daily/weekly),
- по изменениям кода/конфига (git push).

**Шаги:**
1) Загрузка данных из Offline Feature Store.  
2) Валидация данных (leakage, свежесть, корректность логов).  
3) Разбиение train/val/test (желательно time‑based).  
4) Обучение LTR (LambdaMART/LightGBM) + калибровка.  
5) Логирование экспериментов (MLflow): параметры, метрики, артефакты.  
6) Оценка качества: NDCG@K, MAP@K, а также offline‑прокси CTR/CVR uplift.  
7) Quality gates: минимальный NDCG@K + ограничение «latency proxy» (сложность модели).  
8) Регистрация в Model Registry (версионирование).  
9) Вкатка через canary → постепенный rollout.
<img width="1429" height="385" alt="image" src="https://github.com/user-attachments/assets/50b9553d-a25d-4783-b277-e8fc4303922b" />

---

### 2.4. Inference Pipeline (Serving)

**Критический путь запроса (190 мс):**
1) Edge cache (если hit — сразу ответ).  
2) API Gateway (аутентификация/лимиты).  
3) Search Platform:
   - Query Understanding (подготовка запроса),
   - Retrieval (Top‑N кандидатов из OpenSearch),
   - Feature lookups (Online Feature Store/KV),
   - Ranking (LTR) → Top‑K,
   - пост‑обработка (фильтры, дедуп, «нет в наличии»).
4) Cache results в Redis (TTL 1–5 мин).  
5) Асинхронно отправить события в Kafka и метрики/логи в наблюдаемость.

**Деградация (fail‑open):**
- при проблемах ранжировщика — отдаём **retrieval‑ранжирование** (BM25/ANN) и сохраняем SLA;
- при недоступности feature store — используем «базовые» фичи (fallback).
<img width="1249" height="712" alt="image" src="https://github.com/user-attachments/assets/7c41db9c-8aa6-4cd7-8cba-c6b26344d0c0" />

---

### 2.5. Data Storage (хранилища и ретеншн)

Data Storage выделяет, где и сколько времени живут данные поисковой системы (как для online, так и для обучения):

**1) Result Cache (Redis, TTL 1–5 мин)**  
- хранит последние ответы (Top-K) по ключу запроса+контекста;  
- цель: снизить задержку и нагрузку на ранжирование при повторяющихся запросах.

**2) Online Feature Store / KV (near-real-time)**  
- ключ-значение витрины для быстрых онлайн-lookup’ов: цена/наличие/промо, агрегаты CTR/CVR, фичи товара/пользователя;  
- обновляется потоково/микробатчами (из Kafka/ETL), используется Feature Service на инференсе.

**3) Search Index (OpenSearch)**  
- инвертированный индекс для BM25 + ANN-вектора (если используем семантический retrieval);  
- принимает обновления из каталога (reindex/update) и отдаёт Retrieval Service top-N кандидатов.

**4) Results DB (PostgreSQL, last ~30 days)**  
- хранит историю выдач/аудит/диагностику качества (например, какие товары были показаны);  
- полезно для расследований инцидентов, сверки экспериментов и построения отчётности.

**5) Data Lake (Iceberg/Parquet)**  
- сырые логи (queries/impressions/clicks/orders) + снапшоты каталога;  
- является источником правды для пересборки датасетов и воспроизводимости обучения.

**6) Iceberg Snapshots / Object Storage (S3)**  
- snapshots обеспечивают историчность данных для retraining/backtesting;  
- S3 используется для архивов и бэкапов (Results DB backup, snapshots индекса, логи).

**7) Model Artifacts Store (ONNX, checkpoints)**  
- артефакты моделей и калибраторов, метаданные версий;  
- бэкап в объектное хранилище, совместим с Model Registry.

Соответственно, online-запрос обслуживается преимущественно за счёт **Redis + OpenSearch + Online KV**, а контур обучения и воспроизводимости — через **Data Lake + Snapshots + Offline features + Artifacts**.

<img width="1265" height="505" alt="image" src="https://github.com/user-attachments/assets/9aa46f7e-d115-4b1c-a42c-f21cc4a19cf0" />


## Часть 3. Расчёты и нефункциональные требования

Ниже расчёты сделаны на основе явных допущений (как в примере). Цель — получить порядок величин для проектирования.

### 3.1. Расчёт требований к хранилищу

**Допущения:**
- среднее число поисковых запросов на пользователя: **20 запросов/день**;
- на запрос в среднем **20 показов** (impressions);
- средний размер события:
  - query event: **~1 КБ**,
  - impression event: **~0.2 КБ**,
  - click event: **~0.2 КБ**, среднее **0.8 клика/запрос**,
  - order event: **~0.3 КБ**, доля заказов от кликов **2%**.

**Количество запросов в день:**
- 3 858 438 DAU × 20 = **77 168 760 запросов/день**

**Объём логов в день (порядок):**
- query: 77.2M × 1KB ≈ **77 ГБ/день**
- impressions: 77.2M × 20 × 0.2KB ≈ **309 ГБ/день**
- clicks: 77.2M × 0.8 × 0.2KB ≈ **12 ГБ/день**
- orders: 77.2M × 0.8 × 2% × 0.3KB ≈ **0.4 ГБ/день**

**Итого:** ≈ **0.37 ТБ/день**, с накладными расходами (формат, индексы, служебные поля) округляем до **~0.4 ТБ/день**.

**Ретеншн 30 дней (Data Lake raw):**
- 0.4 ТБ/день × 30 ≈ **12 ТБ**
- с резервом (компрессия/версии/схемы) → **15–20 ТБ**

**Дополнительно:**
- Offline features + training datasets: **~5–10 ТБ** (зависит от числа фич и горизонта истории)
- Model artifacts + registry: **~50–200 ГБ**
- Search index (примерно): для 10M товаров:
  - инвертированный индекс + метаданные + вектора + overhead + репликация → **~100–300 ГБ**

---

### 3.2. Расчёт требований к пропускной способности (Throughput)

**Пик:** 12 051 RPS.

**Оценка сетевого трафика:**
- входящий запрос: ~2 КБ (query + контекст)  
  → 12 051 × 2KB ≈ **23.5 МБ/с**
- исходящий ответ: ~5 КБ (Top‑K + метаданные)  
  → 12 051 × 5KB ≈ **58.8 МБ/с**

**Пропускная способность сервиса ранжирования:**
- допущение: 1 pod (CPU‑оптимизированный) выдерживает **~2 000 RPS** при p95 < 190 мс (двухэтапная схема retrieval + fast LTR).

**Требуемое число pod’ов:**
- 12 051 / 2 000 ≈ **6.0 → 7 pod’ов**
- с запасом на отказ и пики (×2) и разнесением по зонам: **12–16 pod’ов** + HPA.

**Kafka (оценка порядка):**
- средняя QPS событий:
  - queries: 77.2M/день ≈ 893/s
  - impressions: 1.54B/день ≈ 17 860/s
- на пике возможен рост кратно (3–5×), поэтому Kafka проектируется с запасом по партициям и брокерам.

---

### 3.3. Масштабируемость, надёжность и эксплуатация

**Масштабируемость:**
- Search Platform (Kubernetes): горизонтальное масштабирование (HPA по CPU/RPS/latency).
- Search index: шардинг + репликация (масштаб по read‑нагрузке).
- Feature store/KV: горизонтальное масштабирование по ключам (consistent hashing/partitioning).
- Kafka: увеличение числа партиций для тем (impressions/clicks/orders).

**Надёжность и отказоустойчивость:**
- Разнесение по 2–3 зонам доступности, репликация сервисов.
- Circuit breakers/таймауты на вызовы (feature store, index).
- Деградация: при сбое LTR → fallback на retrieval (BM25/ANN).
- Canary rollout моделей (10% → 100%) + быстрый rollback.
- Резервное копирование:
  - snapshots индекса,
  - бэкапы Results DB,
  - архив логов в S3.

**Мониторинг и алертинг:**
- технические метрики: p50/p95 latency, RPS, error rate, CPU/RAM, cache hit rate;
- продуктовые метрики: CTR@K, CVR, revenue/margin per search, доля пустых выдач;
- мониторинг дрейфа: распределения запросов, сдвиги категорий, ухудшение калибровки.

---

## Список использованных источников

- Xu, A. *System Design Interview* (подход к проектированию высоконагруженных систем).  
- Apache Kafka Documentation.  
- Kubernetes Documentation.  
- OpenSearch Documentation.  
- Apache Iceberg Documentation.  
- LightGBM Documentation (LTR / LambdaMART).  
